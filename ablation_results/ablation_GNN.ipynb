{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407736cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gaoyiming/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "# ## whole 40 df\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "# ---------- CONFIG ----------\n",
    "folder_path = \"mouse_GRN\"\n",
    "file_pattern = os.path.join(folder_path, \"whole_*.txt\")\n",
    "trrust_path = \"trrust_rawdata.mouse.tsv\"\n",
    "nes_threshold = 3.0\n",
    "genie3_threshold = 0.003\n",
    "MODEL_NAME      = \"gemini-2.0-pro-exp-02-05\"\n",
    "MODEL_PROVIDER  = \"google\"\n",
    "N_NEG_PER_POS   = 1        # class balance; 1 negative for each positive\n",
    "OUTFILE     = \"mouse_GRN/3_llm_reasoning_log_Stomach.jsonl\"     # one JSON row per question\n",
    "TASK_DF_LOCATION = \"mouse_GRN/3_Stomach_tasks.csv\" ### modify this\n",
    "RESULT_OUTPUT_LOCATION = \"mouse_GRN/3_Stomach_score.txt\"\n",
    "TEST_EVAL = \"mouse_GRN/3_Stomach_cutoff_test.csv\"\n",
    "# GCN model parameters\n",
    "PREDICT_CONTEXT = \"Stomach\"\n",
    "epochs = 20               ###### increase  this \n",
    "MAX_PROMPT_LEN  = 4096     # guardrail\n",
    "LEARNING_RATE=1e-2\n",
    "### LLM parameters:\n",
    "BINARY_CUTOFF = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17329a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1.  LOAD DATA ----------------------------------------------------------\n",
    "trrust_df = pd.read_csv(\n",
    "    trrust_path,\n",
    "    sep=\"\\t\",\n",
    "    names=[\"TF\", \"Target\", \"Mode\", \"PMID\"]\n",
    ")\n",
    "all_dfs = []\n",
    "\n",
    "for file_path in glob.glob(file_pattern):\n",
    "    df = pd.read_csv(file_path, sep=\"\\t\")\n",
    "    \n",
    "    # Filter for \"High\" confidence\n",
    "    df_filtered = df[df[\"Confidence\"] == \"High\"].copy()\n",
    "    \n",
    "    # Additional filters\n",
    "    df_filtered = df_filtered[\n",
    "        (df_filtered[\"NES\"] >= nes_threshold) & \n",
    "        (df_filtered[\"Genie3Weight\"].notnull()) & \n",
    "        (df_filtered[\"Genie3Weight\"] >= genie3_threshold)\n",
    "    ]\n",
    "    \n",
    "    # Extract context from filename\n",
    "    filename = os.path.basename(file_path)\n",
    "    context = filename.replace(\"whole_\", \"\").replace(\"-regulons.txt\", \"\")\n",
    "    \n",
    "    # Add context column\n",
    "    df_filtered[\"Context\"] = context\n",
    "    \n",
    "    all_dfs.append(df_filtered)\n",
    "\n",
    "# Combine all filtered dataframes\n",
    "df_combined = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "df_combined[\"Context\"] = df_combined[\"Context\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ca32c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total binary questions: 46  (23 positives)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd, numpy as np, re, ast, json\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
    "from utils.LLM import query_llm\n",
    "\n",
    "# --- 2.  TASK BUILDER -------------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "#  2‑bis.  TASK BUILDER  (train‑pool  →  held‑out graph)\n",
    "# ---------------------------------------------------------------------\n",
    "def build_tasks_multi(df, trrust,\n",
    "                      train_ctxs,           # list of training Context names\n",
    "                      test_ctx,             # single held‑out Context name\n",
    "                      n_neg_per_pos=1,\n",
    "                      max_known=50):  \n",
    "    \"\"\"Return a list[dict] where each dict is one binary TF-gene question.\"\"\"\n",
    "    \n",
    "    df_train = df[df.Context.isin(train_ctxs)].copy()\n",
    "    df_test  = df.query(\"Context == @test_ctx\").copy()\n",
    "    \n",
    "    tasks = []\n",
    "    \n",
    "    # ---- TFs that have at least one edge in *both* pools --------------\n",
    "    tf_common = set(df_train.TF).intersection(df_test.TF)\n",
    "    \n",
    "    for tf in tf_common:\n",
    "        # ----------------  context A  (union over 39 graphs)  ----------\n",
    "        known_A = (\n",
    "            df_train.loc[df_train.TF == tf, \"gene\"]\n",
    "                     .unique()\n",
    "                     .tolist()\n",
    "        )\n",
    "        context_A = df_train.loc[df_train.TF == tf, \"Context\"].unique().tolist()\n",
    "        if not known_A:\n",
    "            continue\n",
    "        \n",
    "        # ----------------  context B  (held‑out graph)  ----------------\n",
    "        cand_B = (\n",
    "            df_test.loc[df_test.TF == tf, \"gene\"]\n",
    "                    .unique()\n",
    "                    .tolist()\n",
    "        )\n",
    "        if not cand_B:\n",
    "            continue\n",
    "        \n",
    "        # ----------------  positives / negatives -----------------------\n",
    "        pos_set = set(trrust[trrust.TF == tf].Target) & set(cand_B)\n",
    "        neg_set = set(cand_B) - pos_set\n",
    "        \n",
    "        if len(pos_set) == 0 or len(neg_set) == 0:\n",
    "            continue\n",
    "        \n",
    "        # balanced negative sampling\n",
    "        rng = np.random.default_rng(0)  # reproducible\n",
    "        n_neg = min(len(pos_set)*n_neg_per_pos, len(neg_set))\n",
    "        neg_sample = rng.choice(list(neg_set), size=n_neg, replace=False)\n",
    "        \n",
    "        # build question dicts\n",
    "        for gene, label in (\n",
    "            list(zip(pos_set, [1]*len(pos_set))) +\n",
    "            list(zip(neg_sample, [0]*len(neg_sample)))\n",
    "        ):\n",
    "            tasks.append({\n",
    "                \"TF\"        : tf,\n",
    "                \"gene\"      : gene,\n",
    "                \"context_A\" : context_A,      \n",
    "                \"context_B\" : test_ctx,\n",
    "                \"known_A\"   : known_A[:max_known],\n",
    "                \"label\"     : label\n",
    "            })\n",
    "    return tasks\n",
    "\n",
    "\n",
    "train_contexts  = [c for c in df_combined.Context.unique()\n",
    "                   if c != PREDICT_CONTEXT]\n",
    "tasks = build_tasks_multi(df_combined, trrust_df,\n",
    "                          train_ctxs=train_contexts,\n",
    "                          test_ctx=PREDICT_CONTEXT,\n",
    "                          n_neg_per_pos=1)\n",
    "\n",
    "print(f\"Total binary questions: {len(tasks)}  \"\n",
    "      f\"({sum(t['label'] for t in tasks)} positives)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5bffe59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gaoyiming/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train graphs = ['MammaryGland.Involution', 'NeonatalMuscle', 'MammaryGland.Virgin', 'MesenchymalStemCells', 'FetalKidney', 'FetalLiver', 'PeripheralBlood', 'Spleen', 'FetalLung', 'MammaryGland.Virgin.CD45', 'MammaryGland.Lactation', 'Liver', 'BoneMarrowcKit', 'NeonatalRib', 'Kidney', 'MammaryGland.Pregnancy', 'SmallIntestine', 'Testis', 'Ovary', 'Prostate', 'TrophoblastStemCells', 'FetalStomach', 'FetalIntestine', 'Lung', 'BoneMarrow', 'EmbryonicMesenchyme', 'Bladder', 'Brain', 'NeonatalSkin', 'NeonatalHeart', 'NeonatalCalvaria', 'MammaryGland.Involution.CD45', 'Muscle', 'FetalBrain', 'EmbryonicStemCells', 'Thymus', 'Placenta', 'Uterus', 'NeonatalPancreas', 'SmallIntestine.CD45']\n",
      "test  graph  = 'Stomach'\n",
      "train edges = 337,025 | test edges = 12,783\n",
      "epoch 020 | loss = 0.6387\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 0.  Imports & helpers\n",
    "# ---------------------------------------------------------------------\n",
    "import torch, torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn   import GCNConv\n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, roc_auc_score\n",
    "import random, warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)   # PyG verbosity\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 1.  Select which graphs are train vs. test\n",
    "# ---------------------------------------------------------------------\n",
    "# -- YOUR df_combined must contain at least the columns\n",
    "#    'TF', 'gene', 'Genie3Weight', 'Context'\n",
    "# ---------------------------------------------------------------------\n",
    "# 39 training contexts  ->  put the names in a list\n",
    "train_contexts = [ctx for ctx in df_combined[\"Context\"].unique().tolist() if ctx != PREDICT_CONTEXT]\n",
    "test_context   = PREDICT_CONTEXT          # held‑out graph\n",
    "\n",
    "df_train = df_combined[df_combined.Context.isin(train_contexts)].copy()\n",
    "df_test  = df_combined.query(\"Context == @test_context\").copy()\n",
    "\n",
    "print(f\"train graphs = {train_contexts!r}\")\n",
    "print(f\"test  graph  = {test_context!r}\")\n",
    "print(f\"train edges = {len(df_train):,d} | test edges = {len(df_test):,d}\")\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 2.  Shared node index across *all* graphs\n",
    "# ---------------------------------------------------------------------\n",
    "all_nodes = pd.Index(df_combined.TF).union(df_combined.gene)\n",
    "node2idx  = {n: i for i, n in enumerate(all_nodes)}\n",
    "num_nodes = len(all_nodes)\n",
    "\n",
    "def edges_to_index(df):\n",
    "    src = df.TF  .map(node2idx).to_numpy()\n",
    "    dst = df.gene.map(node2idx).to_numpy()\n",
    "    return torch.as_tensor(np.vstack([src, dst]), dtype=torch.long)\n",
    "\n",
    "edge_index_train  = edges_to_index(df_train)\n",
    "edge_weight_train = torch.tensor(df_train.Genie3Weight.values,\n",
    "                                 dtype=torch.float32)\n",
    "\n",
    "edge_index_test   = edges_to_index(df_test)          # for later\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 3.  Node features – simple trainable embeddings\n",
    "# ---------------------------------------------------------------------\n",
    "feat_dim = 128\n",
    "x_embed  = torch.nn.Embedding(num_nodes, feat_dim)\n",
    "\n",
    "# PyG Data object that *includes* edge weights\n",
    "data = Data(x=x_embed.weight,\n",
    "            edge_index=edge_index_train,\n",
    "            edge_weight=edge_weight_train)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 4.  GCN encoder + dot‑product decoder (unchanged)\n",
    "# ---------------------------------------------------------------------\n",
    "class GCNLink(torch.nn.Module):\n",
    "    def __init__(self, in_dim, hid=64):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_dim, hid)\n",
    "        self.conv2 = GCNConv(hid,  hid)\n",
    "\n",
    "    def forward(self, x, edge_index, w):\n",
    "        h = F.relu(self.conv1(x, edge_index, w))\n",
    "        h = self.conv2(h, edge_index, w)\n",
    "        return h\n",
    "\n",
    "def dot_score(h, pairs):                       # pairs = 2×N indices\n",
    "    return (h[pairs[0]] * h[pairs[1]]).sum(dim=-1)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 5.  Negative‑edge sampler (uniform corruption, unchanged)\n",
    "# ---------------------------------------------------------------------\n",
    "pos_set = set(zip(edge_index_train[0].tolist(),\n",
    "                  edge_index_train[1].tolist()))\n",
    "\n",
    "def sample_neg(num_neg):\n",
    "    u = torch.randint(0, num_nodes, (num_neg,))\n",
    "    v = torch.randint(0, num_nodes, (num_neg,))\n",
    "    mask = torch.tensor([(u[i].item(), v[i].item()) not in pos_set\n",
    "                         for i in range(num_neg)])\n",
    "    return torch.stack([u[mask], v[mask]], 0)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 6.  Training loop\n",
    "# ---------------------------------------------------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "data   = data.to(device)\n",
    "model  = GCNLink(feat_dim).to(device)\n",
    "\n",
    "opt    = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    model.train(); opt.zero_grad()\n",
    "    h = model(data.x, data.edge_index, data.edge_weight)\n",
    "\n",
    "    # positive & negative scores\n",
    "    pos_s = dot_score(h, data.edge_index)\n",
    "    neg_i = sample_neg(pos_s.size(0)).to(device)\n",
    "    neg_s = dot_score(h, neg_i)\n",
    "\n",
    "    y_true = torch.cat([torch.ones_like(pos_s), torch.zeros_like(neg_s)])\n",
    "    y_pred = torch.cat([pos_s,              neg_s            ])\n",
    "    loss   = F.binary_cross_entropy_with_logits(y_pred, y_true)\n",
    "\n",
    "    loss.backward(); opt.step()\n",
    "\n",
    "    if epoch % 20 == 0:\n",
    "        print(f\"epoch {epoch:03d} | loss = {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfed1b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total binary questions: 46  (23 positives)\n",
      "Precision = 0.51\n",
      "Recall    = 0.96\n",
      "F1 score  = 0.67\n",
      "AUROC     = 0.63\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# 7.  Embeddings for *all* nodes after training\n",
    "# ---------------------------------------------------------------------\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    H = model(data.x, data.edge_index, data.edge_weight).cpu()\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 8.  Helper: evaluate on a paired‑question list (unchanged API)\n",
    "# ---------------------------------------------------------------------\n",
    "from torch.nn.functional import sigmoid\n",
    "\n",
    "def gcn_predict(tasks, H, node2idx, thresh=0.5):\n",
    "    y_true, y_pred, y_score = [], [], []\n",
    "    for t in tasks:\n",
    "        i_tf   = node2idx.get(t[\"TF\"])\n",
    "        i_gene = node2idx.get(t[\"gene\"])\n",
    "        if i_tf is None or i_gene is None:      # unseen node guard\n",
    "            continue\n",
    "        logit = torch.dot(H[i_tf], H[i_gene]).item()\n",
    "        prob  = sigmoid(torch.tensor(logit)).item()\n",
    "        y_true.append(t[\"label\"])\n",
    "        y_score.append(prob)\n",
    "        y_pred.append(1 if prob >= thresh else 0)\n",
    "    return np.array(y_true), np.array(y_pred), np.array(y_score)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 9.  Example evaluation\n",
    "#     (replace `tasks` with your actual paired‑question list)\n",
    "# ---------------------------------------------------------------------\n",
    "y_true_gcn_whole, y_pred_gcn_whole, y_score_gcn_whole = gcn_predict(tasks, H, node2idx)\n",
    "\n",
    "def evaluate(y_true, y_pred, y_score):\n",
    "    p,r,f,_ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average=\"binary\", zero_division=0\n",
    "    )\n",
    "    try:\n",
    "        auc = roc_auc_score(y_true, y_score)\n",
    "    except ValueError:\n",
    "        auc = float(\"nan\")\n",
    "    print(f\"Precision = {p:.2f}\\nRecall    = {r:.2f}\"\n",
    "          f\"\\nF1 score  = {f:.2f}\\nAUROC     = {auc:.2f}\")\n",
    "    return (f\"{p:.2f}\",f\"{r:.2f}\",f\"{f:.2f}\",f\"{auc:.2f}\")\n",
    "    \n",
    "\n",
    "Precision,Recall,F1, AUROC = evaluate(y_true_gcn_whole, y_pred_gcn_whole, y_score_gcn_whole)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1422870",
   "metadata": {},
   "source": [
    "## trying GAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "057f4cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# 4‑bis.  GAT encoder + dot‑product decoder\n",
    "#         (replace the old Section 4 with this block)\n",
    "# ---------------------------------------------------------------------\n",
    "from torch_geometric.nn import GATConv          # NEW import\n",
    "\n",
    "class GATLink(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Two layer GAT.\n",
    "      • First layer: 8 attention heads, ELU activation, concat=True  \n",
    "      • Second layer: 1 head, concat=False to return hidden dim size\n",
    "      • Edge weights are passed as a 1D edge_attr so the attention\n",
    "        mechanism can learn to incorporate Genie3 scores.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim, hid=64, heads=8, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.conv1 = GATConv(\n",
    "            in_channels=in_dim,\n",
    "            out_channels=hid,\n",
    "            heads=heads,\n",
    "            edge_dim=1,          # <‑‑ one scalar per edge\n",
    "            dropout=dropout\n",
    "        )\n",
    "        self.conv2 = GATConv(\n",
    "            in_channels=hid * heads,   # because concat=True above\n",
    "            out_channels=hid,\n",
    "            heads=1,\n",
    "            concat=False,              # keep hidden size = hid\n",
    "            edge_dim=1,\n",
    "            dropout=dropout\n",
    "        )\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        edge_attr = edge_weight.unsqueeze(-1)        # shape [E, 1]\n",
    "        h = F.elu(self.conv1(x, edge_index, edge_attr))\n",
    "        h = self.conv2(h, edge_index, edge_attr)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51563d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_2 = 5e-3\n",
    "epoch_2 = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6a05ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GATLink(feat_dim, hid=64, heads=8, dropout=0.1).to(device)\n",
    "opt    = torch.optim.Adam(model.parameters(), lr=learning_rate_2)\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    model.train(); opt.zero_grad()\n",
    "    h = model(data.x, data.edge_index, data.edge_weight)\n",
    "\n",
    "    # positive & negative scores\n",
    "    pos_s = dot_score(h, data.edge_index)\n",
    "    neg_i = sample_neg(pos_s.size(0)).to(device)\n",
    "    neg_s = dot_score(h, neg_i)\n",
    "\n",
    "    y_true = torch.cat([torch.ones_like(pos_s), torch.zeros_like(neg_s)])\n",
    "    y_pred = torch.cat([pos_s,              neg_s            ])\n",
    "    loss   = F.binary_cross_entropy_with_logits(y_pred, y_true)\n",
    "\n",
    "    loss.backward(); opt.step()\n",
    "\n",
    "    if epoch % 2 == 0:\n",
    "        print(f\"epoch {epoch:03d} | loss = {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2f9583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# 7.  Embeddings for *all* nodes after training\n",
    "# ---------------------------------------------------------------------\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    H = model(data.x, data.edge_index, data.edge_weight).cpu()\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 8.  Helper: evaluate on a paired‑question list (unchanged API)\n",
    "# ---------------------------------------------------------------------\n",
    "from torch.nn.functional import sigmoid\n",
    "\n",
    "def gcn_predict(tasks, H, node2idx, thresh=0.5):\n",
    "    y_true, y_pred, y_score = [], [], []\n",
    "    for t in tasks:\n",
    "        i_tf   = node2idx.get(t[\"TF\"])\n",
    "        i_gene = node2idx.get(t[\"gene\"])\n",
    "        if i_tf is None or i_gene is None:      # unseen node guard\n",
    "            continue\n",
    "        logit = torch.dot(H[i_tf], H[i_gene]).item()\n",
    "        prob  = sigmoid(torch.tensor(logit)).item()\n",
    "        y_true.append(t[\"label\"])\n",
    "        y_score.append(prob)\n",
    "        y_pred.append(1 if prob >= thresh else 0)\n",
    "    return np.array(y_true), np.array(y_pred), np.array(y_score)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 9.  Example evaluation\n",
    "#     (replace `tasks` with your actual paired‑question list)\n",
    "# ---------------------------------------------------------------------\n",
    "y_true_gcn_whole, y_pred_gcn_whole, y_score_gcn_whole = gcn_predict(tasks, H, node2idx)\n",
    "\n",
    "def evaluate(y_true, y_pred, y_score):\n",
    "    p,r,f,_ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average=\"binary\", zero_division=0\n",
    "    )\n",
    "    try:\n",
    "        auc = roc_auc_score(y_true, y_score)\n",
    "    except ValueError:\n",
    "        auc = float(\"nan\")\n",
    "    print(f\"Precision = {p:.2f}\\nRecall    = {r:.2f}\"\n",
    "          f\"\\nF1 score  = {f:.2f}\\nAUROC     = {auc:.2f}\")\n",
    "    return (f\"{p:.2f}\",f\"{r:.2f}\",f\"{f:.2f}\",f\"{auc:.2f}\")\n",
    "    \n",
    "\n",
    "Precision,Recall,F1, AUROC = evaluate(y_true_gcn_whole, y_pred_gcn_whole, y_score_gcn_whole)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
